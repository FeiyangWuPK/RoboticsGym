# environment and task
env:
  name: Humanoid
  task: HUmanoid
  exp_name: ${env.name}_humanoid
  library: omniisaacgymenvs
  max_episode_steps: 1000
  seed: 42
  num_envs: 10

# collector
collector:
  total_frames: 1_000_000
  init_random_frames: 25000
  frames_per_batch: 1000
  init_env_steps: 1000
  device: gpu
  env_per_collector: 1
  reset_at_each_iter: False

# replay buffer
replay_buffer:
  size: 1000000
  prb: 0 # use prioritized experience replay
  scratch_dir: ${env.exp_name}_${env.seed}

# optim
optim:
  utd_ratio: 1.0
  gamma: 0.99
  loss_function: l2
  lr: 3.0e-4
  weight_decay: 0.0
  batch_size: 256
  target_update_polyak: 0.995
  alpha_init: 1.0
  adam_eps: 1.0e-8

# network
network:
  hidden_sizes: [256, 256]
  activation: relu
  default_policy_scale: 1.0
  scale_lb: 0.1
  device: "cuda:0"

# logging
logger:
  backend: csv
  mode: online
  eval_iter: 25000


# Task name - used to pick the class to load
task_name: ${task.name}
# experiment name. defaults to name of training config
experiment: ''

# if set to positive integer, overrides the default number of environments
num_envs: ''

# seed - set to -1 to choose random seed
seed: 42
# set to True for deterministic performance
torch_deterministic: False

# set the maximum number of learning iterations to train for. overrides default per-environment setting
max_iterations: ''

## Device config
physics_engine: 'physx'
# whether to use cpu or gpu pipeline
pipeline: 'gpu'
# whether to use cpu or gpu physx
sim_device: 'gpu'
# used for gpu simulation only - device id for running sim and task if pipeline=gpu
device_id: 0
# device to run RL
rl_device: 'cuda:0'
# multi-GPU training
multi_gpu: False

## PhysX arguments
num_threads: 4 # Number of worker threads per scene used by PhysX - for CPU PhysX only.
solver_type: 1 # 0: pgs, 1: tgs

# RLGames Arguments
# test - if set, run policy in inference mode (requires setting checkpoint to load)
test: False
# used to set checkpoint path
checkpoint: ''
# evaluate checkpoint
evaluation: False

# disables rendering
headless: True
# enables native livestream
enable_livestream: False
# timeout for MT script
mt_timeout: 90

wandb_activate: False
wandb_group: ''
wandb_name: ${train.params.config.name}
wandb_entity: ''
wandb_project: 'omniisaacgymenvs'

# path to a kit app file
kit_app: ''

# Warp
warp: False

# # set default task and default training config based on task
defaults:
  - _self_
  - task: Cartpole
  - train: ${task}PPO
  - override hydra/job_logging: disabled

# set the directory where the output files get saved
hydra:
  output_subdir: null
  run:
    dir: .

