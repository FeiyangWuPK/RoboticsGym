{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Append path: /home/anduril/catkin_ws/src/digit_gym_clean_RL to sys.path\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "path = os.path.abspath('../')\n",
    "sys.path.append(str(path))\n",
    "print('Append path: ' + str(path) + ' to sys.path')\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.registration import register\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import mujoco\n",
    "\n",
    "register(id='Digit-v3',\n",
    "\t\tentry_point='digit_viz:DigitEnv',\n",
    "\t\tmax_episode_steps=1000,\n",
    "\t\tautoreset=True,)\n",
    "\n",
    "register(id='Cassie-v1',\n",
    "\t\tentry_point='mj_cassie:CassieEnv',\n",
    "\t\tmax_episode_steps=1000,\n",
    "\t\tautoreset=True,)\n",
    "\n",
    "register(id='CassieViz-v1',\n",
    "\t\tentry_point='cassie_viz:CassieEnv',\n",
    "\t\tmax_episode_steps=1000,\n",
    "\t\tautoreset=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.25986685e-01,  1.89389405e-01,  9.55490435e-01,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -1.82236918e-02,\n",
       "        1.34376717e-02,  8.27486761e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.73924659e+00,  8.50879968e-04,\n",
       "        1.96522114e+00,  0.00000000e+00, -1.85146112e+00,  0.00000000e+00,\n",
       "       -1.85146112e+00,  2.40834984e-02, -9.87883627e-03,  4.79081375e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.27109483e+00, -6.12753419e-02,  1.61933244e+00,  0.00000000e+00,\n",
       "       -1.65400232e+00,  0.00000000e+00, -1.65400232e+00])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs = make_vec_env(\"CassieViz-v1\", n_envs=1, env_kwargs={'exclude_current_positions_from_observation': False, 'render_mode': 'human'})\n",
    "env = envs.envs[0]\n",
    "env.model.opt.timestep\n",
    "env.frame_skip\n",
    "env.init_qpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anduril/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 10.78GB > 10.76GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:253\u001b[0m, in \u001b[0;36m_keep_alive\u001b[0;34m(x, memo)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     memo[\u001b[39mid\u001b[39;49m(memo)]\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m    254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[39m# aha, this is the first one :-)\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 140665580912000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m SAC(\u001b[39m\"\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m \t\t\tenvs,\n\u001b[1;32m      3\u001b[0m \t\t\tverbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m      4\u001b[0m \t\t\tlearning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m,)\n\u001b[0;32m----> 5\u001b[0m mean_reward, std_reward \u001b[39m=\u001b[39m evaluate_policy(model, envs, render\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, n_eval_episodes\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:94\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mwhile\u001b[39;00m (episode_counts \u001b[39m<\u001b[39m episode_count_targets)\u001b[39m.\u001b[39many():\n\u001b[1;32m     88\u001b[0m     actions, states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m     89\u001b[0m         observations,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         state\u001b[39m=\u001b[39mstates,\n\u001b[1;32m     91\u001b[0m         episode_start\u001b[39m=\u001b[39mepisode_starts,\n\u001b[1;32m     92\u001b[0m         deterministic\u001b[39m=\u001b[39mdeterministic,\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 94\u001b[0m     new_observations, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m     95\u001b[0m     current_rewards \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m rewards\n\u001b[1;32m     96\u001b[0m     current_lengths \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:72\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menvs[env_idx]\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obs_from_buf(), np\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews), np\u001b[39m.\u001b[39mcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones), deepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuf_infos))\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:205\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    203\u001b[0m append \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mappend\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n\u001b[0;32m--> 205\u001b[0m     append(deepcopy(a, memo))\n\u001b[1;32m    206\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:177\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n\u001b[1;32m    176\u001b[0m     memo[d] \u001b[39m=\u001b[39m y\n\u001b[0;32m--> 177\u001b[0m     _keep_alive(x, memo) \u001b[39m# Make sure x lives at least as long as d\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.8/copy.py:253\u001b[0m, in \u001b[0;36m_keep_alive\u001b[0;34m(x, memo)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Keeps a reference to the object x in the memo.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[39mBecause we remember objects by their id, we have\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mthe memo itself...\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     memo[\u001b[39mid\u001b[39;49m(memo)]\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m    254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[39m# aha, this is the first one :-)\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     memo[\u001b[39mid\u001b[39m(memo)]\u001b[39m=\u001b[39m[x]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SAC(\"MlpPolicy\",\n",
    "\t\t\tenvs,\n",
    "\t\t\tverbose=0,\n",
    "\t\t\tlearning_rate=1e-3,)\n",
    "mean_reward, std_reward = evaluate_policy(model, envs, render=True, n_eval_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anduril/.local/lib/python3.8/site-packages/glfw/__init__.py:916: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\",\n",
    "\t\t\tenvs,\n",
    "            learning_rate=1e-3,\n",
    "\t\t\tverbose=1)\n",
    "mean_reward, std_reward = evaluate_policy(model, envs, render=True, n_eval_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005\n",
      "5\n",
      "[ 1.62422803e+00 -2.74737256e-02  1.01854151e+00  1.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.95267333e-01\n",
      "  2.59242753e-03  2.02006095e-01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  3.63361699e-01 -2.26981220e-02\n",
      " -3.15269005e-01 -2.18936907e-02 -4.38871903e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -9.96320522e-03\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  1.67022233e-02 -8.88278765e-02 -1.42914279e-01  1.09086647e+00\n",
      "  5.59902988e-04 -1.40124351e-01 -2.78477434e-01  2.59242753e-03\n",
      " -3.36900531e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -2.70939357e-01 -1.13011241e-02  2.93565573e-01\n",
      " -9.32483825e-03  2.53505665e-01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.68676527e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.16439523e-01\n",
      "  1.30889901e-01  1.43935335e-01 -1.09005634e+00 -3.75825293e-04\n",
      "  1.40162701e-01]\n",
      "torso/base\n",
      "left-leg/hip-roll\n",
      "left-leg/hip-yaw\n",
      "left-leg/hip-pitch\n",
      "left-leg/achilles-rod\n",
      "left-leg/knee\n",
      "left-leg/shin\n",
      "left-leg/tarsus\n",
      "left-leg/heel-spring\n",
      "left-leg/toe-a\n",
      "left-leg/toe-a-rod\n",
      "left-leg/toe-b\n",
      "left-leg/toe-b-rod\n",
      "left-leg/toe-pitch\n",
      "left-leg/toe-roll\n",
      "left-arm/shoulder-roll\n",
      "left-arm/shoulder-pitch\n",
      "left-arm/shoulder-yaw\n",
      "left-arm/elbow\n",
      "right-leg/hip-roll\n",
      "right-leg/hip-yaw\n",
      "right-leg/hip-pitch\n",
      "right-leg/achilles-rod\n",
      "right-leg/knee\n",
      "right-leg/shin\n",
      "right-leg/tarsus\n",
      "right-leg/heel-spring\n",
      "right-leg/toe-a\n",
      "right-leg/toe-a-rod\n",
      "right-leg/toe-b\n",
      "right-leg/toe-b-rod\n",
      "right-leg/toe-pitch\n",
      "right-leg/toe-roll\n",
      "right-arm/shoulder-roll\n",
      "right-arm/shoulder-pitch\n",
      "right-arm/shoulder-yaw\n",
      "right-arm/elbow\n",
      "[ 0  7  8  9 10 14 15 16 17 18 19 23 24 28 29 30 31 32 33 34 35 36 37 41\n",
      " 42 43 44 45 46 50 51 55 56 57 58 59 60]\n",
      "[ 0  6  7  8  9 12 13 14 15 16 17 20 21 24 25 26 27 28 29 30 31 32 33 36\n",
      " 37 38 39 40 41 44 45 48 49 50 51 52 53]\n"
     ]
    }
   ],
   "source": [
    "envs = make_vec_env(\"Digit-v3\", n_envs=1, env_kwargs={'exclude_current_positions_from_observation': False, 'render_mode': 'human'})\n",
    "env = envs.envs[0]\n",
    "print(env.model.opt.timestep)\n",
    "print(env.frame_skip)\n",
    "print(env.init_qpos)\n",
    "# Print all body names and the address in the qpos array.\n",
    "for joint_id in env.model.jnt_bodyid:\n",
    "  print(mujoco.mj_id2name(env.model, mujoco.mjtObj.mjOBJ_BODY, joint_id))\n",
    "print(env.model.jnt_qposadr)\n",
    "print(env.model.jnt_dofadr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anduril/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 16.17GB > 10.23GB\n",
      "  warnings.warn(\n",
      "/home/anduril/.local/lib/python3.8/site-packages/glfw/__init__.py:916: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    }
   ],
   "source": [
    "model = SAC(\"MlpPolicy\",\n",
    "\t\t\tenvs,\n",
    "\t\t\tverbose=0,\n",
    "\t\t\tlearning_rate=1e-3,)\n",
    "mean_reward, std_reward = evaluate_policy(model, envs, render=True, n_eval_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
